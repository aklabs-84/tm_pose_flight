// tm_core_services_pose.js
// TMCore v1.0 (Pose ì „ìš©) â€” ModelService / CameraService / ResultService
// UIì™€ ì™„ì „ ë¶„ë¦¬. window.TMCorePoseë¡œ export.
// í•„ìš” ìŠ¤í¬ë¦½íŠ¸(HTMLì—ì„œ ë¡œë“œ):
// <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
// <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>

(function (global) {
  // ===== ê³µí†µ =====
  const _normUrl = (u='') => {
    let s = (u || '').trim();
    if (!s) return '';
    // ëŒ€ëµì  ê²€ì¦ + ìŠ¬ë˜ì‹œ ë³´ì •
    const ok = /^https?:\/\/teachablemachine\.withgoogle\.com\/models\/[A-Za-z0-9_-]+\/?$/.test(s);
    if (!ok) console.warn('[TMCorePose] ëª¨ë¸ URL í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
    return s.endsWith('/') ? s : s + '/';
  };
  const _assert = (cond, msg) => { if (!cond) throw new Error(msg); };

  // ===== ModelService (Pose) =====
  const ModelService = (() => {
    let model = null;
    let labels = [];
    let lastPose = null;

    async function load(baseUrl) {
      const base = _normUrl(baseUrl);
      _assert(!!base, 'ëª¨ë¸ URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.');
      const metaURL  = base + 'metadata.json';
      const modelURL = base + 'model.json';
      const bust = '?v=' + Date.now();
      try {
        // CORS/404 ë¹ ë¥¸ í™•ì¸
        const metaResp = await fetch(metaURL, { cache:'no-store', mode:'cors' });
        if (!metaResp.ok) {
          throw new Error('ë©”íƒ€ë°ì´í„° ì‘ë‹µ ì˜¤ë¥˜: ' + metaResp.status + ' - ' + metaURL);
        }
        const meta = await metaResp.json();
        labels = Array.isArray(meta.labels) ? meta.labels : [];

        // TM Pose ëª¨ë¸ ë¡œë“œ
        model = await tmPose.load(modelURL + bust, metaURL + bust);
        if (!labels.length && model.getClassLabels) labels = model.getClassLabels();
        if (!labels || !labels.length) throw new Error('í´ë˜ìŠ¤ ë¼ë²¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. metadata.json í™•ì¸ í•„ìš”');
        return { labels: labels.slice() };
      } catch (err) {
        console.error('[TMCorePose] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', err);
        // ì¬ë°œì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•´ ì›ë˜ ì—ëŸ¬ë¥¼ ìƒìœ„ë¡œ ì „ë‹¬
        throw err;
      }
    }

    function _ensure(){ _assert(!!model, 'Model not loaded'); }

    async function estimate(videoEl) {
      _ensure();
      _assert(videoEl && videoEl.videoWidth > 0, 'ìœ íš¨í•œ ë¹„ë””ì˜¤/í”„ë ˆì„ í•„ìš”');
      const { pose, posenetOutput } = await model.estimatePose(videoEl);
      lastPose = pose;
      return { pose, posenetOutput };
    }

    async function classify(posenetOutput) {
      _ensure(); _assert(!!posenetOutput, 'posenet ì¶œë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.');
      const predictions = await model.predict(posenetOutput); // [{className, probability}]
      return predictions;
    }

    async function predictFromVideo(videoEl) {
      const { pose, posenetOutput } = await estimate(videoEl);
      const preds = await classify(posenetOutput);
      return { pose, preds };
    }

    const getLabels = () => labels.slice();
    const getLastPose = () => lastPose;
    const isLoaded = () => !!model;

    return { load, estimate, classify, predictFromVideo, getLabels, getLastPose, isLoaded };
  })();

  // ===== CameraService =====
  const CameraService = (() => {
    let stream = null;

    async function start(videoEl, opts = { facingMode:'user' }) {
      _assert(!!videoEl, 'video ì—˜ë¦¬ë¨¼íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.');
      stream = await navigator.mediaDevices.getUserMedia({ video: opts, audio: false });
      videoEl.srcObject = stream;
      await videoEl.play();
      return stream;
    }
    function stop(){ if (stream){ stream.getTracks().forEach(t=>t.stop()); stream = null; } }
    const hasStream = () => !!stream;

    function capture(videoEl, canvasEl){
      _assert(videoEl && videoEl.videoWidth>0, 'í™œì„± ë¹„ë””ì˜¤ í•„ìš”');
      const c = canvasEl || document.createElement('canvas');
      c.width = videoEl.videoWidth; c.height = videoEl.videoHeight;
      c.getContext('2d').drawImage(videoEl,0,0);
      return c;
    }

    return { start, stop, hasStream, capture };
  })();

  // ===== ResultService =====
  const ResultService = (() => {
    const defaultEmojiMap = {
      'squat':'ğŸ‹ï¸','pose':'ğŸ§˜','left':'â¬…ï¸','right':'â¡ï¸','up':'â¬†ï¸','down':'â¬‡ï¸','jump':'ğŸ¦˜','arm':'ğŸ’ª','leg':'ğŸ¦µ','plank':'ğŸ“'
    };

    const sort = (preds)=>preds.slice().sort((a,b)=>b.probability - a.probability);
    const topK  = (preds,k=3)=>sort(preds).slice(0,k);
    const mapEmoji = (label, map=defaultEmojiMap)=>{
      const low=(label||'').toLowerCase();
      const key=Object.keys(map).find(k=>low.includes(k));
      return key? map[key] : 'âœ¨';
    };

    return { sort, topK, mapEmoji, defaultEmojiMap };
  })();

  // ===== Export =====
  global.TMCorePose = { ModelService, CameraService, ResultService };
})(window);
